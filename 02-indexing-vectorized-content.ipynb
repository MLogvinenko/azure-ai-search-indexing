{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Prerequisites\n",
    "\n",
    "Before executing this notebook, make sure you have properly set up your Azure Services, created your Conda environment, and configured your environment variables as per the instructions provided in the [README.md](README.md) file.\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "This notebook guides you through the following sections:\n",
    "\n",
    "1. [**Create Azure AI Search Indexes**](#create-index): We'll create two indexes. The first index will contain content extracted from documents in SharePoint Online and Blob Storage. The second index will be dedicated to storing image and audio extracted metadata from Blob Storage.\n",
    "\n",
    "2. [**Indexing Vectorized Content from Documents**](#index-documents)\n",
    "    - Chunk, vectorize, and index local PDF files and website addresses.\n",
    "    - Download, chunk, vectorize, and index all `.docx` files from a SharePoint site.\n",
    "    - Download, process complex OCR using GPT-4 Vision, chunk, vectorize, and index PDF files originally stored in Blob Storage and now indexed in Azure AI Search.\n",
    "\n",
    "3. [**Indexing Vectorized Content from Images**](#index-images)\n",
    "    - Process complex OCR and computer vision capabilities using GPT-4 Vision, chunk, vectorize, and index images with extracted metadata, originally stored in Blob Storage and now indexed in Azure AI Search.\n",
    "\n",
    "4. [**Indexing Vectorized Content from Audio**](#index-audio)\n",
    "    - Process MP3 audio data using Azure AI Speech Translator capabilities, chunk, vectorize, and index audio files originally stored in Blob Storage and now indexed in Azure AI Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "#### Configure Environment Variables \n",
    "\n",
    "Before running this notebook, you must configure certain environment variables. We will now use environment variables to store our configuration. This is a more secure practice as it prevents sensitive data from being accidentally committed and pushed to version control systems.\n",
    "\n",
    "Create a `.env` file in your project root (use the provided `.env.sample` as a template) and add the following variables:\n",
    "\n",
    "```env\n",
    "# Azure AI Search Service Configuration\n",
    "AZURE_AI_SEARCH_SERVICE_ENDPOINT=\"<Your Azure Search Service Endpoint>\"\n",
    "AZURE_SEARCH_ADMIN_KEY=\"<Your Azure Search Admin Key>\"\n",
    "AZURE_SEARCH_INDEX_NAME_DOCUMENTS=\"<Your Azure Search Index Name for Documents>\"\n",
    "AZURE_SEARCH_INDEX_NAME_IMAGES_AND_AUDIO=\"<Your Azure Search Index Name for Images and Audio>\"\n",
    "\n",
    "# Azure Speech Service Configuration\n",
    "SPEECH_KEY=\"<Your Azure Speech Service Subscription Key>\"\n",
    "SPEECH_REGION=\"<Your Azure Speech Service Region>\"\n",
    "\n",
    "# Azure OpenAI Configuration\n",
    "AZURE_OPENAI_API_KEY=\"<Your OpenAI API Key>\"\n",
    "AZURE_OPENAI_ENDPOINT=\"<Your OpenAI Endpoint>\"\n",
    "AZURE_OPENAI_API_VERSION=\"<Your Azure OpenAI API Version>\"\n",
    "\n",
    "# Azure Storage Configuration\n",
    "AZURE_STORAGE_CONNECTION_STRING=\"<Your Azure Storage Connection String>\"\n",
    "```\n",
    "\n",
    "Replace the placeholders (e.g., [Your Azure Search Service Endpoint]) with your actual values.\n",
    "\n",
    "- `AZURE_AI_SEARCH_SERVICE_ENDPOINT` and `AZURE_SEARCH_ADMIN_KEY` are used to configure the Azure AI Search service.\n",
    "- `SPEECH_KEY` and `SPEECH_REGION` are used to configure the Azure Speech service.\n",
    "- `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, and `AZURE_OPENAI_API_VERSION` are used to configure the Azure OpenAI service.\n",
    "- `AZURE_STORAGE_CONNECTION_STRING` is used to configure the Azure Storage service.\n",
    "\n",
    "> ðŸ“Œ **Note**\n",
    "> Remember not to commit the .env file to your version control system. Add it to your .gitignore file to prevent it from being tracked.\n",
    "\n",
    "#### Setting Up Conda Environment and Configuring VSCode for Jupyter Notebooks (Optional)\n",
    "\n",
    "Follow these steps to create a Conda environment and set up your VSCode for running Jupyter Notebooks:\n",
    "\n",
    "##### Create Conda Environment from the Repository\n",
    "\n",
    "> Instructions for Windows users: \n",
    "\n",
    "1. **Create the Conda Environment**:\n",
    "   - In your terminal or command line, navigate to the repository directory.\n",
    "   - Execute the following command to create the Conda environment using the `environment.yaml` file:\n",
    "     ```bash\n",
    "     conda env create -f environment.yaml\n",
    "     ```\n",
    "   - This command creates a Conda environment as defined in `environment.yaml`.\n",
    "\n",
    "2. **Activating the Environment**:\n",
    "   - After creation, activate the new Conda environment by using:\n",
    "     ```bash\n",
    "     conda activate vector-indexing-azureaisearch\n",
    "     ```\n",
    "\n",
    "> Instructions for Linux users (or Windows users with WSL or other linux setup): \n",
    "\n",
    "1. **Use `make` to Create the Conda Environment**:\n",
    "   - In your terminal or command line, navigate to the repository directory and look at the Makefile.\n",
    "   - Execute the `make` command specified below to create the Conda environment using the `environment.yaml` file:\n",
    "     ```bash\n",
    "     make create_conda_env\n",
    "     ```\n",
    "\n",
    "2. **Activating the Environment**:\n",
    "   - After creation, activate the new Conda environment by using:\n",
    "     ```bash\n",
    "     conda activate vector-indexing-azureaisearch\n",
    "     ```\n",
    "\n",
    "##### Configure VSCode for Jupyter Notebooks\n",
    "\n",
    "1. **Install Required Extensions**:\n",
    "   - Download and install the `Python` and `Jupyter` extensions for VSCode. These extensions provide support for running and editing Jupyter Notebooks within VSCode.\n",
    "\n",
    "2. **Open the Notebook**:\n",
    "   - Open the Jupyter Notebook file (`01-indexing-content.ipynb`) in VSCode.\n",
    "\n",
    "3. **Attach Kernel to VSCode**:\n",
    "   - After creating the Conda environment, it should be available in the kernel selection dropdown. This dropdown is located in the top-right corner of the VSCode interface.\n",
    "   - Select your newly created environment (`vector-indexing-azureaisearch`) from the dropdown. This sets it as the kernel for running your Jupyter Notebooks.\n",
    "\n",
    "4. **Run the Notebook**:\n",
    "   - Once the kernel is attached, you can run the notebook by clicking on the \"Run All\" button in the top menu, or by running each cell individually.\n",
    "\n",
    "\n",
    "By following these steps, you'll establish a dedicated Conda environment for your project and configure VSCode to run Jupyter Notebooks efficiently. This environment will include all the necessary dependencies specified in your `environment.yaml` file. If you wish to add more packages or change versions, please use `pip install` in a notebook cell or in the terminal after activating the environment, and then restart the kernel. The changes should be automatically applied after the session restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-search-indexing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-search-indexing\"  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure AI Search Indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `TextChunkingIndexing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 01:51:03,965 - micro - MainProcess - INFO     Loading OpenAIEmbeddings object with model, deployment foundational-ada, and chunk size 1000 (langchain_integration_azureai.py:load_embedding_model:113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 01:51:05,605 - micro - MainProcess - INFO     AzureOpenAIEmbeddings object created successfully. (langchain_integration_azureai.py:load_embedding_model:124)\n"
     ]
    }
   ],
   "source": [
    "# Import the TextChunkingIndexing class from the langchain_integration module\n",
    "from src.gbb_ai.langchain_integration_azureai import TextChunkingIndexing\n",
    "\n",
    "# Create an instance of the TextChunkingIndexing class\n",
    "gbb_ai_client = TextChunkingIndexing()\n",
    "\n",
    "# load the environment variables from the .env file\n",
    "gbb_ai_client.load_environment_variables_from_env_file()\n",
    "\n",
    "# Specify the name of the deployment in Azure AI Services\n",
    "DEPLOYMENT_NAME = \"foundational-ada\"\n",
    "\n",
    "# Load the embedding model associated with the specified deployment\n",
    "embedding_model = gbb_ai_client.load_embedding_model(azure_deployment=DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/Load the Azure AI Search Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the Azure Search index\n",
    "# This is the index where your data is stored in Azure Search\n",
    "INDEX_NAME = \"index-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Search Fields with Azure AI\n",
    "\n",
    "In this section, we define the fields that will be used for indexing and searching in Azure AI. These fields represent the different pieces of data that Azure AI will use to understand and categorize the information, enabling more efficient and accurate search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchFieldDataType,\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SemanticSettings,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    ")\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, filterable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_model.embed_query(\"Text\")),\n",
    "        vector_search_configuration=\"default\",\n",
    "    ),\n",
    "    SearchableField(name=\"metadata\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SimpleField(name=\"source\", type=SearchFieldDataType.String, filterable=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Semantic Search Parameters\n",
    "\n",
    "In this section, we set up the configuration for semantic search. Semantic search is a type of information retrieval that focuses on the meaning of queries, rather than just matching keywords. It uses natural language processing (NLP) and other advanced techniques to understand the context and intent behind a user's search query, providing more relevant and accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_settings_config = [\n",
    "    SemanticConfiguration(\n",
    "        name=\"config\",\n",
    "        prioritized_fields=PrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"content\"),\n",
    "            prioritized_content_fields=[SemanticField(field_name=\"content\")],\n",
    "            prioritized_keywords_fields=[SemanticField(field_name=\"metadata\")],\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 01:55:09,525 - micro - MainProcess - INFO     Azure Cognitive Search client configured successfully. (langchain_integration_azureai.py:setup_azure_search:222)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.azuresearch.AzureSearch at 0x20a9785dca0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the Azure Search client with the specified index\n",
    "# This prepares the client to interact with the Azure Search service\n",
    "gbb_ai_client.setup_azure_search(\n",
    "    index_name=INDEX_NAME,\n",
    "    fields=fields,\n",
    "    semantic_settings_config=semantic_settings_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 01:59:26,727 - micro - MainProcess - INFO     Reading PDF files from C:\\Users\\pablosal\\Desktop\\gbbai-langchain-azureai-search\\utils\\data\\ultraflex_user_manual.pdf. (langchain_integration_azureai.py:read_and_load_pdfs:320)\n",
      "2023-12-21 01:59:51,660 - micro - MainProcess - INFO     Starting to embed and index 39 chuncks. (langchain_integration_azureai.py:embed_and_index:387)\n",
      "2023-12-21 02:00:43,435 - micro - MainProcess - INFO     Successfully embedded and indexed 39 chuncks. (langchain_integration_azureai.py:embed_and_index:389)\n"
     ]
    }
   ],
   "source": [
    "# Scrap web and chuck files intp sentences\n",
    "# Define the URLs of the web pages to scrape\n",
    "file_1 = \"utils\\\\data\\\\ultraflex_user_manual.pdf\"\n",
    "\n",
    "# Set the chunk size and overlap size for splitting the text\n",
    "CHUNK_SIZE = 512\n",
    "OVERLAP_SIZE = 128\n",
    "SEPARATOR = \"(\\n\\w|\\w\\n)\"\n",
    "\n",
    "# Scrape the web pages, split the text into chunks, and store the chunks\n",
    "# The text is split into chunks of size CHUNK_SIZE, with an overlap of OVERLAP_SIZE between consecutive chunks\n",
    "text_chuncked = gbb_ai_client.load_and_split_text_by_character_from_pdf(\n",
    "    source=file_1, chunk_size=CHUNK_SIZE, chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "\n",
    "# Embed the chunks and index them in Azure Search\n",
    "# This function converts the text chunks into vector embeddings and stores them in the Azure Search index\n",
    "gbb_ai_client.embed_and_index(text_chuncked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-your-own-copilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
