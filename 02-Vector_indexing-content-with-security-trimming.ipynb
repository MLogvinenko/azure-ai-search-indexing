{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time SharePoint Document Indexing with Security Trimming via Graph API and Azure AI Search\n",
    "\n",
    "Leverage the Microsoft [Graph API](https://learn.microsoft.com/en-us/sharepoint/dev/apis/sharepoint-rest-graph) in combination with Azure AI Search to index SharePoint Online documents in real-time.It employs [Langchain](https://python.langchain.com/docs/integrations/vectorstores/azuresearch) as a high-level orchestration tool for chunking and vectorizing text, harnessing Ada from Azure OpenAI to transform SharePoint text into meaningful vectors This solution excels in tracking document updates and applying [security trimming](https://learn.microsoft.com/en-us/azure/search/search-security-trimming-for-azure-search) to align search results with user access levels. Additionally, it enhances the search experience by enabling hybrid + reranking ([RRF](https://learn.microsoft.com/en-us/azure/search/hybrid-search-ranking)) features, utilizing state-of-the-art, out-of-the-box relevance scoring provided by Azure AI search. With Azure AI as the vector store, users benefit from advanced search capabilities, including more accurate and contextually relevant results.\n",
    "\n",
    "\n",
    "#### Flow\n",
    "\n",
    "1. [Extracting Files from SharePoint with SharePointDataExtractor](#extracting-files-from-sharepoint-with-sharepointdataextractor)\n",
    "2. [Chunking, Text Vectorization, and Indexing with TextChunkingIndexing](#chunking-text-vectorization-and-indexing-with-textchunkingindexing)\n",
    "3. [Search with Embedded Security Trimming Intelligence](#search-with-security-trimming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequesites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify `target_directory` in the code to match the path of your desired directory before executing the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "target_directory = r'C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search'\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Conda Environment and Configuring VSCode for Jupyter Notebooks\n",
    "\n",
    "Follow these steps to create a Conda environment and set up your VSCode for running Jupyter Notebooks:\n",
    "\n",
    "##### Create Conda Environment from the Repository\n",
    "\n",
    "1. **Prepare the Environment File**:\n",
    "   - Ensure you have an `environment.yml` file in your repository. This file should list all the necessary libraries and dependencies for your project.\n",
    "\n",
    "2. **Use `make` to Create the Conda Environment**:\n",
    "   - In your terminal or command line, navigate to the repository directory and look at the Makefile.\n",
    "   - Execute the `make` command specified below to create the Conda environment using the `environment.yml` file:\n",
    "     \n",
    "     ```bash\n",
    "     make create_conda_env\n",
    "     ```\n",
    "\n",
    "   - This command runs a `make` target that creates a Conda environment as defined in `environment.yml`.\n",
    "\n",
    "3. **Activating the Environment**:\n",
    "   - After creation, activate the new Conda environment by using:\n",
    "     ```bash\n",
    "     conda activate [YourEnvName]\n",
    "     ```\n",
    "     Replace `[YourEnvName]` with the name of your environment as specified in `environment.yml`.\n",
    "\n",
    "##### Configure VSCode for Jupyter Notebooks\n",
    "\n",
    "1. **Install Required Extensions**:\n",
    "   - Download and install the `Python` and `Jupyter` extensions in VSCode.\n",
    "\n",
    "2. **Attach Kernel to VSCode**:\n",
    "   - Once the Conda environment is created, you should be able to see it in the kernel selection (top right corner of your VSCode interface).\n",
    "   - Select your newly created environment as the kernel for running Jupyter Notebooks.\n",
    "\n",
    "By following these steps, you'll set up a dedicated Conda environment for your project and configure VSCode to run Jupyter Notebooks efficiently. This environment will contain all the necessary dependencies in your `environment.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Azure AI Services for Running This Notebook\n",
    "\n",
    "+ *Azure Cognitive Search*: This service is crucial for indexing and querying large amounts of data. It provides advanced search capabilities, including full-text search, AI-powered insights, and rich data integration.\n",
    "\n",
    "+ *Azure OpenAI Service*: Utilized for leveraging advanced AI models like Ada for text vectorization and other AI-based tasks. \n",
    "\n",
    "+ *Microsoft Graph API*: Essential for accessing SharePoint Online data. It allows the notebook to authenticate, access documents, and understand document-level permissions within SharePoint. To run the notebook with Microsoft Graph API for accessing SharePoint Online data, you need to register an application in Azure. This process involves several steps:\n",
    "    - Sign in to the [Azure portal](https://portal.azure.com/) as the Admin you copied from above/\n",
    "    - If you have access to multiple tenants, use the Directories + subscriptions filter  in the top menu to switch to the tenant in which you want to register the application.\n",
    "    - Search for and select Azure Active Directory.\n",
    "    - Under Manage, select App registrations > New registration.\n",
    "    - Enter a Name for your application, for example <code>sharepoint-cog-search-indexing</code>. Users of your app might see this name, and you can change it later.\n",
    "    - Select Register.\n",
    "    - Under Manage, select Certificates & secrets.\n",
    "    - Under Client secrets, select New client secret, enter a name, and then select Add. Record the value which will be the \"Client Secret\" in a safe location for use in a later step. NOTE: Do no copy the \"Secredt ID\" as this is not needed.\n",
    "    - Under Manage, select API Permissions > Add a permission. Select Microsoft Graph.\n",
    "    - Select Application permissions.\n",
    "    - Under User node, select User.Read.All as well as Site.Read.All, then select Add permissions.\n",
    "    - If you notice that \"Grant Admin Consent\" is required, enable this now. Make sure all permissions have been granted admin consent. If you require an Admin, please see this [document](https://learn.microsoft.com/azure/active-directory/develop/console-app-quickstart?pivots=devlang-python) for additional help.\n",
    "    - Click \"Overview\" and copy the \"Application (client) ID\" as well as the \"Directory (tenant) ID\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Environment Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load secrets and configurations for your notebook, you will use environment variables. These variables should be defined in a .env file, which you need to create and fill with your specific keys and service endpoints. *Refer to .env.sample for Guidance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Variables Needed\n",
    "\n",
    "# SharePoint Configuration\n",
    "SITE_DOMAIN = 'mngenvmcap747548.sharepoint.com'  # Domain of your SharePoint site\n",
    "SITE_NAME = 'Contoso'                           # Name of your SharePoint site\n",
    "\n",
    "# Azure Open AI Deployment Configuration\n",
    "DEPLOYMENT = \"foundational-ada\"                 # Deployment name for your Azure Open AI service needed for text embeddings\n",
    "MODEL_NAME = \"text-embedding-ada-002\"           # Model name for text embeddings in Azure Open AI service\n",
    "\n",
    "# Azure AI Search Index Configuration\n",
    "INDEX_NAME = \"langchain-vector-demo-custom\"     # Name of the index in Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting Files from SharePoint with `SharePointDataExtractor`\n",
    "\n",
    "The `SharePointDataExtractor` class, built atop the official SDK, streamlines interactions with Microsoft SharePoint through the Microsoft Graph API, focusing on efficient data retrieval and permissions management.\n",
    "\n",
    "#### Key Features:\n",
    "\n",
    "- **Authentication**: Automates OAuth with Microsoft Graph API using tenant ID, client ID, and client secret.\n",
    "- **Data Retrieval**: Retrieves site and drive IDs, and files from SharePoint sites.\n",
    "- **File Processing**: Filters and processes files, primarily .docx (extensible to other formats), based on modification time and type.\n",
    "- **Permissions Management**: Analyzes file permissions for understanding access controls and associated roles.\n",
    "- **Data Extraction**: Compiles detailed information about files, including content, location, and user roles, into a structured format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbb_ai.sharepoint_data_extractor import SharePointDataExtractor\n",
    "\n",
    "# Instantiate the SharePointDataExtractor client\n",
    "# The client handles the complexities of interacting with SharePoint's REST API, providing an easy-to-use interface for data extraction.\n",
    "client_scrapping = SharePointDataExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 17:00:28,038 - micro - MainProcess - INFO     New access token retrieved.... (sharepoint_data_extractor.py:msgraph_auth:59)\n",
      "2023-12-11 17:00:28,040 - micro - MainProcess - INFO     Decoded Access Token:\n",
      "{\n",
      "  \"aud\": \"https://graph.microsoft.com\",\n",
      "  \"iss\": \"https://sts.windows.net/9495d8c9-4ebb-4107-b905-c7b45d1b7b7a/\",\n",
      "  \"iat\": 1702335327,\n",
      "  \"nbf\": 1702335327,\n",
      "  \"exp\": 1702339227,\n",
      "  \"aio\": \"E2VgYNj8br7t7bUmT1h/Ha+ZnzS3FgA=\",\n",
      "  \"app_displayname\": \"dev-graph\",\n",
      "  \"appid\": \"118583ee-94ed-45dd-870b-73784045eb37\",\n",
      "  \"appidacr\": \"1\",\n",
      "  \"idp\": \"https://sts.windows.net/9495d8c9-4ebb-4107-b905-c7b45d1b7b7a/\",\n",
      "  \"idtyp\": \"app\",\n",
      "  \"oid\": \"4f614374-65fa-45fc-8369-cb616a6fe08f\",\n",
      "  \"rh\": \"0.Ab0AydiVlLtOB0G5Bce0XRt7egMAAAAAAAAAwAAAAAAAAADLAAA.\",\n",
      "  \"roles\": [\n",
      "    \"TeamsActivity.Read.All\",\n",
      "    \"SharePointTenantSettings.Read.All\",\n",
      "    \"People.Read.All\",\n",
      "    \"Group.Read.All\",\n",
      "    \"Sites.Read.All\",\n",
      "    \"Group.ReadWrite.All\",\n",
      "    \"Sites.Manage.All\",\n",
      "    \"Directory.Read.All\",\n",
      "    \"OnlineMeetingTranscript.Read.All\",\n",
      "    \"BrowserSiteLists.ReadWrite.All\",\n",
      "    \"GroupMember.Read.All\",\n",
      "    \"Files.Read.All\",\n",
      "    \"Mail.Read\",\n",
      "    \"Chat.Read.All\",\n",
      "    \"GroupMember.ReadWrite.All\"\n",
      "  ],\n",
      "  \"sub\": \"4f614374-65fa-45fc-8369-cb616a6fe08f\",\n",
      "  \"tenant_region_scope\": \"NA\",\n",
      "  \"tid\": \"9495d8c9-4ebb-4107-b905-c7b45d1b7b7a\",\n",
      "  \"uti\": \"iaQH_cYw_0-MQ9fYEZhhAA\",\n",
      "  \"ver\": \"1.0\",\n",
      "  \"wids\": [\n",
      "    \"0997a1d0-0d1d-4acb-b408-d5ca73121e90\"\n",
      "  ],\n",
      "  \"xms_tcdt\": 1697638621\n",
      "} (sharepoint_data_extractor.py:msgraph_auth:75)\n",
      "2023-12-11 17:00:28,040 - micro - MainProcess - INFO     Token Expires at: 2023-12-11 18:00:27 (sharepoint_data_extractor.py:msgraph_auth:79)\n",
      "2023-12-11 17:00:28,041 - micro - MainProcess - INFO     Getting the Site ID... (sharepoint_data_extractor.py:get_site_id:121)\n",
      "2023-12-11 17:00:29,160 - micro - MainProcess - INFO     Site ID retrieved: mngenvmcap747548.sharepoint.com,877fe60f-a62d-4ed1-8eda-af543c437d2c,ac47d8a7-cd54-4344-bd9d-26ada5a075c0 (sharepoint_data_extractor.py:get_site_id:125)\n",
      "2023-12-11 17:00:29,859 - micro - MainProcess - INFO     Making request to Microsoft Graph API (sharepoint_data_extractor.py:get_files_in_site:170)\n",
      "2023-12-11 17:00:30,559 - micro - MainProcess - INFO     Received response from Microsoft Graph API (sharepoint_data_extractor.py:get_files_in_site:173)\n",
      "2023-12-11 17:00:30,561 - micro - MainProcess - INFO     Fetching content for file: test.docx (sharepoint_data_extractor.py:retrieve_sharepoint_files_content:335)\n",
      "2023-12-11 17:00:30,561 - micro - MainProcess - INFO     Starting request for file: test.docx (sharepoint_data_extractor.py:get_docx_content:272)\n",
      "2023-12-11 17:00:32,051 - micro - MainProcess - INFO     Successfully retrieved content for file: test.docx (sharepoint_data_extractor.py:get_docx_content:288)\n",
      "2023-12-11 17:00:33,051 - micro - MainProcess - INFO     Returning highest priority group: Group_critical (azure_search_security_trimming.py:get_highest_priority_group:47)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve .docx file contents from a specified SharePoint site using SharePointDataExtractor\n",
    "content_files = client_scrapping.retrieve_sharepoint_files_content(site_domain=SITE_DOMAIN, site_name=SITE_NAME, minutes_ago=None,file_formats=[\"docx\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chunking, Text Vectorization, and Indexing with `TextChunkingIndexing`\n",
    "\n",
    "The `TextChunkingIndexing` simplifies the role in chunking, text vectorization, and indexing in Azure AI Search acting as Vector Database. It utilizes Langchain as an orchestrator to simplify and enhance the text proccesing strategy. More about Ai search and LangChain integration [here](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-cognitive-search-and-langchain-a-seamless-integration-for/ba-p/3901448)\n",
    "\n",
    "#### Key Features of `TextChunkingIndexing`:\n",
    "\n",
    "- **Text Chunking**: Breaks down extensive text data into smaller chunks based on character count, facilitating easier analysis and indexing.\n",
    "- **Customization**: Allows for the adjustment of chunk size and overlap, catering to various text processing needs.\n",
    "- **Text Vectorization**: Transforms the chunked text into vector representations, essential for efficient indexing and retrieval.\n",
    "- **Indexing to Vector Store**: The vectorized text is then indexed into Azure AI Search, a powerful vector database for storing and retrieving text data.\n",
    "\n",
    "#### Importance of Chunking Fine-tuning and overlapping:\n",
    "\n",
    "- Fine-tuning chunk sizes and overlaps is critical for optimizing text retrieval quality, particularly in applications requiring precise search functionalities (relevance), like RAGs. More about fine tuning and aunderatand releveance scores [here](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-cognitive-search-outperforming-vector-search-with-hybrid/ba-p/3929167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbb_ai.langchain_indexing import TextChunkingIndexing\n",
    "\n",
    "client_indexing = TextChunkingIndexing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 12:39:53,214 - micro - MainProcess - INFO     Loading OpenAIEmbeddings object with model text-embedding-ada-002, deployment foundational-ada, and chunk size 1000 (langchain_indexing.py:load_embedding_model:102)\n",
      "2023-12-10 12:39:53,232 - micro - MainProcess - INFO     OpenAIEmbeddings object created successfully. (langchain_indexing.py:load_embedding_model:115)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, async_client=None, model='text-embedding-ada-002', deployment='foundational-ada', openai_api_version='2023-05-15', openai_api_base='https://ml-workspace-dev-eastus-001-aoai.openai.azure.com/', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='d050ad8b96ef4ecbb5099eece1212a91', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=16, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=True, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the TextChunkingIndexing client\n",
    "# This cleint is resposnsinle for chunking text into smaller pieces using Langchaing framework, which are then indexed by Azure AI Search.\n",
    "client_indexing = TextChunkingIndexing()\n",
    "\n",
    "client_indexing.setup_aoai()\n",
    "\n",
    "client_indexing.load_embedding_model(deployment=DEPLOYMENT,model_name=MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Guide to Setting Up Azure Search Index (Optional)\n",
    "\n",
    "Let's set up an Azure Search index tailored for advanced search capabilities, including semantic and vector-based searches. Here's a step-by-step guide:\n",
    "\n",
    "##### Embedding Function Setup:\n",
    "\n",
    "Define embedding_function to transform text into vectors. This powers the semantic search.\n",
    "\n",
    "##### Define Index Fields:\n",
    "\n",
    "Create fields like id, content, content_vector, and others in the fields list. Each field represents a document attribute.\n",
    "Make sure content_vector aligns with your embedding function's output.\n",
    "\n",
    "##### Initialize Azure Search Client:\n",
    "\n",
    "Instantiate AzureSearch with your Azure endpoint, key, custom index_name, and the fields list.\n",
    "Configure semantic settings to fine-tune search relevance.\n",
    "\n",
    "##### Customize As Needed:\n",
    "\n",
    "Modify fields based on your document attributes.\n",
    "Adjust index_name or semantic configurations to fit your specific search needs.\n",
    "\n",
    "```python \n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchFieldDataType, SimpleField, SearchableField, SemanticSettings, SemanticConfiguration, PrioritizedFields, SemanticField\n",
    ")\n",
    "from azure.search.documents.models import Vector\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from your_embedding_module import embeddings  # Replace with your actual module\n",
    "\n",
    "# Embedding function and fields setup\n",
    "embedding_function = embeddings.embed_query\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, filterable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    # ... other fields ...\n",
    "]\n",
    "\n",
    "# Azure Search client initialization\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_SEARCH_ADMIN_KEY\"),\n",
    "    index_name=\"your-custom-index-name\",\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    "    # Semantic settings\n",
    "    semantic_settings=SemanticSettings(\n",
    "        default_configuration=\"config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"config\",\n",
    "                prioritized_fields=PrioritizedFields(\n",
    "                    title_field=SemanticField(field_name=\"content\"),\n",
    "                    # ... other configurations ...\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Now, your Azure Search index is ready for advanced querying!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.91it/s]\n",
      "2023-12-10 12:40:00,377 - micro - MainProcess - INFO     Azure Cognitive Search client configured successfully. (langchain_indexing.py:setup_azure_search:202)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.azuresearch.AzureSearch at 0x271375885e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the function that will load or create the index mentioned above\n",
    "client_indexing.setup_azure_search(index_name=\"langchain-vector-demo-custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the text from content_files (a list of Document objects) into chunks of 1000 characters and overlap of 200 characters\n",
    "chuncks = client_indexing.split_documents_in_chunks(content_files, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Indexing chunks in Azure AI Search\n",
    "client_indexing.embed_and_index(texts=chuncks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Search with security treamming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r'C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search'\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"langchain-vector-demo-custom\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbb_ai.trimming_ai_search import AzureSearchManager\n",
    "\n",
    "client_search = AzureSearchManager(index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admins']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_groups = client_search.get_current_user_groups()\n",
    "user_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"LLM in International Business Law\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_group=\"Group_criticaldfvdm;mvs\"\n",
    "security_group_list=[\"Group_critical\",\"Group_high\",\"Group_medium\",\"Group_low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\sharepoint-indexing\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "2023-12-11 17:13:17,458 - micro - MainProcess - INFO     Search Results:\n",
      "Result 1:\n",
      "Score: 0.026480834931135178\n",
      "Reranker Score: 2.258655071258545\n",
      "Content: A large language model (LLM) is a type of language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by using massive amounts of data to learn billions of parameters during training and consuming large computational resources during their training and operation.[1] LLMs are artificial neural networks (mainly transformers[2]) and are (pre-)trained using self-supervised learning and semi-supervised learning. As autoregressive language models, they work by taking an input text and repeatedly predicting the next token or word.[3] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[4] They are thought to acquire knowledge about syntax, semantics and \"ontology\" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[5]\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Score: 0.027973394840955734\n",
      "Reranker Score: 2.244293689727783\n",
      "Content: Interpretation[edit] Large language models by themselves are \"black boxes\", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work. Mechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[71][72] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[73]\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Score: 0.02982456237077713\n",
      "Reranker Score: 2.1421377658843994\n",
      "Content: In contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[79] or point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[75] For example, GPT-4 has natural deficits in planning and in real-time learning.[77] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[82] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[83] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".[75]\n",
      "--------------------------------------------------\n",
      "Result 4:\n",
      "Score: 0.03226646035909653\n",
      "Reranker Score: 2.1271541118621826\n",
      "Content: Agency[edit] An LLM is a language model, which is not an agent as it has no goal, but it can be used as a component of an intelligent agent.[35] Researchers have described several methods for such integrations. The ReAct (\"Reason+Act\") method constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.[36] The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[37]\n",
      "--------------------------------------------------\n",
      "Result 5:\n",
      "Score: 0.03057890012860298\n",
      "Reranker Score: 2.081317901611328\n",
      "Content: NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[75] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[76][77] Some researchers characterize LLMs as \"alien intelligence\".[78][79] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM:\n",
      "-------------------------------------------------- (trimming_ai_search.py:secure_hybrid_search_rerank:128)\n"
     ]
    }
   ],
   "source": [
    "results = client_search.secure_hybrid_search_rerank(search_query=search_query, security_group=security_group, top_k=5, azure_deployment_name=\"foundational-ada\", semantic_configuration_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A large language model (LLM) is a type of language model notable for its ability to achieve general-purpose language understanding and generation. LLMs acquire these abilities by using massive amounts of data to learn billions of parameters during training and consuming large computational resources during their training and operation.[1] LLMs are artificial neural networks (mainly transformers[2]) and are (pre-)trained using self-supervised learning and semi-supervised learning. As autoregressive language models, they work by taking an input text and repeatedly predicting the next token or word.[3] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[4] They are thought to acquire knowledge about syntax, semantics and \"ontology\" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[5]',\n",
       " \"Flamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.[54] Google PaLM model was finetuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.[55] LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs,[56] and video inputs.[57] GPT-4 can use both text and image as inputs[58] (although the vision component wasn't released to the public until GPT-4V[59]), while Google Gemini is expected to be multimodal.[60] Properties[edit] Scaling laws and emergent abilities[edit] Main article: Neural scaling law The following four hyper-parameters characterize a LLM: cost of (pre-)training (�), size of the artificial neural network itself, such as number of parameters � (i.e. amount of neurons in its layers, amount of weights between them and biases),\",\n",
       " 'NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[75] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[76][77] Some researchers characterize LLMs as \"alien intelligence\".[78][79] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM:',\n",
       " 'example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"[80][81]',\n",
       " 'Interpretation[edit] Large language models by themselves are \"black boxes\", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work. Mechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[71][72] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[73]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not self.token:\n",
    "    logger.error(\"Access token is not available.\")\n",
    "    return []\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {self.token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "endpoint = f\"https://graph.microsoft.com/v1.0/users/{user_id}/memberOf\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        logger.error(f\"Error retrieving user groups: {response.status_code} {response.reason}\")\n",
    "        logger.error(f\"Response content: {response.text}\")\n",
    "        return []\n",
    "    return response.json()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Exception in retrieving user groups: {e}\")\n",
    "    return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharepoint-indexing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
